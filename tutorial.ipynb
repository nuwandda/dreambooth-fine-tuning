{"cells":[{"cell_type":"markdown","metadata":{"id":"OIXhN_Geh9iM"},"source":["# Setup  \n","## Installing Python packages\n","### Basic Python Packages\n","First, we need to install all the necessary libraries. It is recommended to create a new virtual environment before you continue with the installation. After activating your environment, run the commands below.  \n","*NOTE:* We need to install diffusers using the link provided below."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30492,"status":"ok","timestamp":1695382819765,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"-P3D96cxh9iN","outputId":"5fe9f10c-9430-42d3-8743-08e808e3de29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/ShivamShrirao/diffusers.git\n","  Cloning https://github.com/ShivamShrirao/diffusers.git to /tmp/pip-req-build-_5bahi99\n","  Running command git clone --filter=blob:none --quiet https://github.com/ShivamShrirao/diffusers.git /tmp/pip-req-build-_5bahi99\n","  Resolved https://github.com/ShivamShrirao/diffusers.git to commit 2c298300756fa7d8bf644852cffaebc5072f11f6\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (6.8.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (3.12.2)\n","Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (0.17.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (1.23.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (2.31.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.15.0.dev0) (9.4.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (2023.6.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (23.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.15.0.dev0) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0.dev0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0.dev0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0.dev0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.15.0.dev0) (2023.7.22)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.23.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.33.2)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.1.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.13.0)\n","Requirement already satisfied: modelcards in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.1.6)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.44.4)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.0.1+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.17.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.1.2)\n","Collecting triton==2.0.0 (from torch>=1.10.0->accelerate->-r requirements.txt (line 1))\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (4.66.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 4)) (0.2.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.4.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.3.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.41.2)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.103.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.3.1)\n","Requirement already satisfied: gradio-client==0.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.5.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.25.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (6.0.1)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.9.7)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (1.5.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (1.10.12)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.0.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (2.10.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.23.2)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (11.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.1->gradio->-r requirements.txt (line 7)) (2023.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (0.12.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 7)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 7)) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.7.22)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 7)) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 7)) (0.14.0)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 7)) (0.27.0)\n","Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 7)) (0.18.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 7)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->-r requirements.txt (line 7)) (1.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 7)) (0.10.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.3.0)\n","Installing collected packages: triton\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","Successfully installed triton-2.0.0\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n"]}],"source":["!pip install git+https://github.com/ShivamShrirao/diffusers.git\n","!pip install -r requirements.txt\n","!python -m pip install huggingface_hub"]},{"cell_type":"markdown","metadata":{"id":"MAJrW1yfh9iO"},"source":["### xformers Packages\n","At this time, we are using a GPU with a VRAM less than 24GB. Hence, we need to install this package to reduce the use of VRAM. In order to install this package, run the cell below."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5295,"status":"ok","timestamp":1695382825058,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"NbB2C9FXh9iO","outputId":"1590effb-3abc-425e-f0c8-05b976c132f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->xformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->xformers) (1.3.0)\n"]}],"source":["!pip install xformers"]},{"cell_type":"markdown","metadata":{"id":"wNgN7ix3h9iP"},"source":["If you face an issue, use the cell below to install the necessary package using repository."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysRXr29Vh9iP"},"outputs":[],"source":["!pip install git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"]},{"cell_type":"markdown","metadata":{"id":"RlksWsyGh9iP"},"source":["### Accelerate Setup\n","After running the command below, you will see some prompts. Answer it according to your specifications."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32503,"status":"ok","timestamp":1695382873830,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"b-gM00ZMh9iP","outputId":"66a40ebc-9ded-4d6d-ef3a-8a3f8ae9ca4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\rIn which compute environment are you running?\n","Please input a choice index (starting from 0), and press enter\n"," ➔  \u001b[32mThis machine\u001b[0m\r\n","    AWS (Amazon SageMaker)\n","\u001b[2A\u001b[?25l0\n","\u001b[32mThis machine\u001b[0m\n","Which type of machine are you using?\n","Please input a choice index (starting from 0), and press enter\n"," ➔  \u001b[32mNo distributed training\u001b[0m\n","    multi-CPU\n","    multi-XPU\n","    multi-GPU\n","    multi-NPU\n","    TPU\n","\u001b[6A\u001b[?25l*\n","\u001b[32mNo distributed training\u001b[0m\n","\u001b[?25hDo you want to run your training on CPU only (even if a GPU / Apple Silicon / Ascend NPU device is available)? [yes/NO]:No\n","Do you wish to optimize your script with torch dynamo?[yes/NO]:No\n","Do you want to use DeepSpeed? [yes/NO]: no\n","What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:all\n","Do you wish to use FP16 or BF16 (mixed precision)?\n","Please input a choice index (starting from 0), and press enter\n"," ➔  \u001b[32mno\u001b[0m\n","    fp16\n","    bf16\n","    fp8\n","\u001b[4A\u001b[?25lfp16\n","\u001b[32mno\u001b[0m\n","\u001b[?25haccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"]}],"source":["!accelerate config"]},{"cell_type":"markdown","metadata":{"id":"enNNdJH6h9iQ"},"source":["### Install huggingface-cli\n","We need to install huggingface-cli to download the base models. For fine-tuning, we need to use diffusers model instead of ckpt files. First, we need to register an account in HuggingFace. After that, we need to create a token. Visit this *[page](https://huggingface.co/docs/hub/security-tokens)* and create a token.  \n","Then, run the cell below to login using your newly created token."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12104,"status":"ok","timestamp":1695382888528,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"wdTnQJ0kh9iQ","outputId":"0bbfad7b-11bd-43a3-ceef-baf579965f73"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","    \n","    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n","    Setting a new token will erase the existing one.\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"markdown","metadata":{"id":"MTg18s6dh9iQ"},"source":["## Import Required Libraries"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10020,"status":"ok","timestamp":1695382900864,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"ad-h64fzh9iR"},"outputs":[],"source":["import argparse\n","import itertools\n","import math\n","import os\n","from contextlib import nullcontext\n","import random\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.checkpoint\n","from torch.utils.data import Dataset\n","\n","import PIL\n","from accelerate import Accelerator\n","from accelerate.logging import get_logger\n","from accelerate.utils import set_seed\n","from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n","from diffusers.optimization import get_scheduler\n","from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n","from PIL import Image\n","from torchvision import transforms\n","from tqdm.auto import tqdm\n","from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n","\n","import bitsandbytes as bnb"]},{"cell_type":"markdown","metadata":{"id":"wo0NRdoSh9iR"},"source":["# Dataset and Concept\n","We will use an image of a teddy bear. The pictures are taken by myself in my home. First, we will create the links of the images to download it later. 3-5 images should be fine."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1695382903425,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"RyT3dDzbh9iR"},"outputs":[],"source":["urls = [\n","    \"https://huggingface.co/datasets/nuwandaa/teddy-bear/resolve/main/1.jpeg\",\n","    \"https://huggingface.co/datasets/nuwandaa/teddy-bear/resolve/main/2.jpeg\",\n","    \"https://huggingface.co/datasets/nuwandaa/teddy-bear/resolve/main/3.jpeg\",\n","    \"https://huggingface.co/datasets/nuwandaa/teddy-bear/resolve/main/4.jpeg\",\n","    \"https://huggingface.co/datasets/nuwandaa/teddy-bear/resolve/main/5.jpeg\"\n","]"]},{"cell_type":"markdown","metadata":{"id":"sRUzEzpXh9iR"},"source":["Now, we will decide which Stable Diffusion checkpoint we want to use."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1695382905270,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"s1LeTvKBh9iR"},"outputs":[],"source":["pretrained_model_name_or_path = \"stabilityai/stable-diffusion-2\" #@param [\"stabilityai/stable-diffusion-2\", \"stabilityai/stable-diffusion-2-base\", \"CompVis/stable-diffusion-v1-4\", \"runwayml/stable-diffusion-v1-5\"] {allow-input: true}"]},{"cell_type":"markdown","metadata":{"id":"XGjJYIEFh9iS"},"source":["Next step is downloading the images. After downloading them, we will use a grid to see the images."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419,"output_embedded_package_id":"1waRXKbi4O3nIfYUooYfzShJf90F-VIl5"},"executionInfo":{"elapsed":21603,"status":"ok","timestamp":1695382942135,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"t2GWNE8-h9iS","outputId":"5b69d031-894b-4f29-b59e-76f03163e9ef"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import requests\n","import glob\n","from io import BytesIO\n","\n","\n","def image_grid(imgs, rows, cols):\n","    assert len(imgs) == rows*cols\n","\n","    w, h = imgs[0].size\n","    grid = Image.new('RGB', size=(cols*w, rows*h))\n","    grid_w, grid_h = grid.size\n","\n","    for i, img in enumerate(imgs):\n","        grid.paste(img, box=(i%cols*w, i//cols*h))\n","    return grid\n","\n","\n","def download_image(url):\n","  try:\n","    response = requests.get(url)\n","  except:\n","    return None\n","  return Image.open(BytesIO(response.content)).convert(\"RGB\")\n","\n","\n","images = list(filter(None,[download_image(url) for url in urls]))\n","save_path = \"./my_concept\"\n","if not os.path.exists(save_path):\n","  os.mkdir(save_path)\n","[image.save(f\"{save_path}/{i}.jpeg\") for i, image in enumerate(images)]\n","image_grid(images, 1, len(images))"]},{"cell_type":"markdown","metadata":{"id":"qGXyeD5hh9iS"},"source":["We are using a custom dataset and we need to describe our concept clearly. The description should contain a clear description of what your object or style is. The other option is using `prior_preservation`. Prior-preservation is used to avoid overfitting and language-drift. This option helps us to preserve the concept and increases the quality."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":941,"status":"ok","timestamp":1695382950643,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"TZGoZOYsh9iS"},"outputs":[],"source":["instance_prompt = \"<teddy-bear> toy\" #@param {type:\"string\"}\n","prior_preservation = True #@param {type:\"boolean\"}\n","prior_preservation_class_prompt = \"a photo of a teddy bear\" #@param {type:\"string\"}\n","\n","num_class_images = 12\n","sample_batch_size = 2\n","prior_loss_weight = 0.5\n","prior_preservation_class_folder = \"./class_images\"\n","class_data_root=prior_preservation_class_folder\n","class_prompt=prior_preservation_class_prompt\n","\n","num_class_images = 12 #@param {type: \"number\"}\n","sample_batch_size = 2\n","#@markdown `prior_preservation_weight` determins how strong the class for prior preservation should be\n","prior_loss_weight = 1 #@param {type: \"number\"}\n","\n","\n","#@markdown If the `prior_preservation_class_folder` is empty, images for the class will be generated with the class prompt. Otherwise, fill this folder with images of items on the same class as your concept (but not images of the concept itself)\n","prior_preservation_class_folder = \"./class_images\" #@param {type:\"string\"}\n","class_data_root=prior_preservation_class_folder"]},{"cell_type":"markdown","metadata":{"id":"X3gyioPDh9iS"},"source":["# Training\n","### Setting Up the Classes"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":442,"status":"ok","timestamp":1695382952961,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"oxoVItrOh9iS"},"outputs":[],"source":["from pathlib import Path\n","from torchvision import transforms\n","\n","class DreamBoothDataset(Dataset):\n","    def __init__(\n","        self,\n","        instance_data_root,\n","        instance_prompt,\n","        tokenizer,\n","        class_data_root=None,\n","        class_prompt=None,\n","        size=512,\n","        center_crop=False,\n","    ):\n","        self.size = size\n","        self.center_crop = center_crop\n","        self.tokenizer = tokenizer\n","\n","        self.instance_data_root = Path(instance_data_root)\n","        if not self.instance_data_root.exists():\n","            raise ValueError(\"Instance images root doesn't exists.\")\n","\n","        self.instance_images_path = list(Path(instance_data_root).iterdir())\n","        self.num_instance_images = len(self.instance_images_path)\n","        self.instance_prompt = instance_prompt\n","        self._length = self.num_instance_images\n","\n","        if class_data_root is not None:\n","            self.class_data_root = Path(class_data_root)\n","            self.class_data_root.mkdir(parents=True, exist_ok=True)\n","            self.class_images_path = list(Path(class_data_root).iterdir())\n","            self.num_class_images = len(self.class_images_path)\n","            self._length = max(self.num_class_images, self.num_instance_images)\n","            self.class_prompt = class_prompt\n","        else:\n","            self.class_data_root = None\n","\n","        self.image_transforms = transforms.Compose(\n","            [\n","                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n","                transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.5], [0.5]),\n","            ]\n","        )\n","\n","\n","    def __len__(self):\n","        return self._length\n","\n","\n","    def __getitem__(self, index):\n","        example = {}\n","        instance_image = Image.open(self.instance_images_path[index % self.num_instance_images])\n","        if not instance_image.mode == \"RGB\":\n","            instance_image = instance_image.convert(\"RGB\")\n","        example[\"instance_images\"] = self.image_transforms(instance_image)\n","        example[\"instance_prompt_ids\"] = self.tokenizer(\n","            self.instance_prompt,\n","            padding=\"do_not_pad\",\n","            truncation=True,\n","            max_length=self.tokenizer.model_max_length,\n","        ).input_ids\n","\n","        if self.class_data_root:\n","            class_image = Image.open(self.class_images_path[index % self.num_class_images])\n","            if not class_image.mode == \"RGB\":\n","                class_image = class_image.convert(\"RGB\")\n","            example[\"class_images\"] = self.image_transforms(class_image)\n","            example[\"class_prompt_ids\"] = self.tokenizer(\n","                self.class_prompt,\n","                padding=\"do_not_pad\",\n","                truncation=True,\n","                max_length=self.tokenizer.model_max_length,\n","            ).input_ids\n","\n","        return example\n","\n","\n","class PromptDataset(Dataset):\n","    def __init__(self, prompt, num_samples):\n","        self.prompt = prompt\n","        self.num_samples = num_samples\n","\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","\n","    def __getitem__(self, index):\n","        example = {}\n","        example[\"prompt\"] = self.prompt\n","        example[\"index\"] = index\n","        return example"]},{"cell_type":"markdown","metadata":{"id":"nHtNgTTgh9iT"},"source":["### Generating Class Images"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1695382956272,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"cHf0kbjbh9iT"},"outputs":[],"source":["import gc\n","if(prior_preservation):\n","    class_images_dir = Path(class_data_root)\n","    if not class_images_dir.exists():\n","        class_images_dir.mkdir(parents=True)\n","    cur_class_images = len(list(class_images_dir.iterdir()))\n","\n","    if cur_class_images < num_class_images:\n","        pipeline = StableDiffusionPipeline.from_pretrained(\n","            pretrained_model_name_or_path, revision=\"fp16\", torch_dtype=torch.float16\n","        ).to(\"cuda\")\n","        pipeline.enable_attention_slicing()\n","        pipeline.set_progress_bar_config(disable=True)\n","\n","        num_new_images = num_class_images - cur_class_images\n","        print(f\"Number of class images to sample: {num_new_images}.\")\n","\n","        sample_dataset = PromptDataset(class_prompt, num_new_images)\n","        sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=sample_batch_size)\n","\n","        for example in tqdm(sample_dataloader, desc=\"Generating class images\"):\n","            images = pipeline(example[\"prompt\"]).images\n","\n","            for i, image in enumerate(images):\n","                image.save(class_images_dir / f\"{example['index'][i] + cur_class_images}.jpg\")\n","        pipeline = None\n","        gc.collect()\n","        del pipeline\n","\n","        with torch.no_grad():\n","          torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"PONkvSJIh9iT"},"source":["### Load the Stable Diffusion Model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":12833,"status":"ok","timestamp":1695382973059,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"thGx9ybVh9iT"},"outputs":[],"source":["text_encoder = CLIPTextModel.from_pretrained(\n","    pretrained_model_name_or_path, subfolder=\"text_encoder\"\n",")\n","vae = AutoencoderKL.from_pretrained(\n","    pretrained_model_name_or_path, subfolder=\"vae\"\n",")\n","unet = UNet2DConditionModel.from_pretrained(\n","    pretrained_model_name_or_path, subfolder=\"unet\"\n",")\n","tokenizer = CLIPTokenizer.from_pretrained(\n","    pretrained_model_name_or_path,\n","    subfolder=\"tokenizer\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"DuZ3GOmnh9iT"},"source":["### Setting Up Training Arguments\n","The most important thing here is not to over-train our model because the Dreambooth tends to overfit quickly. After training, if your model is not responding well to your prompts, you need to reduce the training steps or train with higher steps using lower learning rate.  \n","\n","Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n","\n","\n","| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n","| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n","| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n","| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n","| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n","| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n","| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n","| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n","| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n","| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n","| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n","  \n","Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n","\n","Remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n","\n","Remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":376,"status":"ok","timestamp":1695382976029,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"cj6zV5OYh9iT"},"outputs":[],"source":["from argparse import Namespace\n","args = Namespace(\n","    pretrained_model_name_or_path=pretrained_model_name_or_path,\n","    resolution=vae.sample_size,\n","    center_crop=True,\n","    train_text_encoder=False,\n","    instance_data_dir=save_path,\n","    instance_prompt=instance_prompt,\n","    learning_rate=5e-06,\n","    max_train_steps=300,\n","    save_steps=50,\n","    train_batch_size=1, # set to 1 if using prior preservation\n","    gradient_accumulation_steps=1,\n","    max_grad_norm=1.0,\n","    mixed_precision=\"fp16\", # set to \"fp16\" for mixed-precision training.\n","    gradient_checkpointing=True, # set this to True to lower the memory usage.\n","    use_8bit_adam=True, # use 8bit optimizer from bitsandbytes\n","    seed=3434554,\n","    with_prior_preservation=prior_preservation,\n","    prior_loss_weight=prior_loss_weight,\n","    sample_batch_size=2,\n","    class_data_dir=prior_preservation_class_folder,\n","    class_prompt=prior_preservation_class_prompt,\n","    num_class_images=num_class_images,\n","    lr_scheduler=\"constant\",\n","    lr_warmup_steps=100,\n","    output_dir=\"dreambooth-concept\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"g4Up1w5sh9iT"},"source":["### Training Functions"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1695382979369,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"yXNIrwgkh9iT"},"outputs":[],"source":["from accelerate.utils import set_seed\n","def training_function(text_encoder, vae, unet):\n","    logger = get_logger(__name__)\n","\n","    set_seed(args.seed)\n","\n","    accelerator = Accelerator(\n","        gradient_accumulation_steps=args.gradient_accumulation_steps,\n","        mixed_precision=args.mixed_precision,\n","    )\n","\n","    # Currently, it's not possible to do gradient accumulation when training two models with accelerate.accumulate\n","    # This will be enabled soon in accelerate. For now, we don't allow gradient accumulation when training two models.\n","    if args.train_text_encoder and args.gradient_accumulation_steps > 1 and accelerator.num_processes > 1:\n","        raise ValueError(\n","            \"Gradient accumulation is not supported when training the text encoder in distributed training. \"\n","            \"Please set gradient_accumulation_steps to 1. This feature will be supported in the future.\"\n","        )\n","\n","    vae.requires_grad_(False)\n","    if not args.train_text_encoder:\n","        text_encoder.requires_grad_(False)\n","\n","    if args.gradient_checkpointing:\n","        unet.enable_gradient_checkpointing()\n","        if args.train_text_encoder:\n","            text_encoder.gradient_checkpointing_enable()\n","\n","    # Use 8-bit Adam for lower memory usage or to fine-tune the model in 16GB GPUs\n","    if args.use_8bit_adam:\n","        optimizer_class = bnb.optim.AdamW8bit\n","    else:\n","        optimizer_class = torch.optim.AdamW\n","\n","    params_to_optimize = (\n","        itertools.chain(unet.parameters(), text_encoder.parameters()) if args.train_text_encoder else unet.parameters()\n","    )\n","\n","    optimizer = optimizer_class(\n","        params_to_optimize,\n","        lr=args.learning_rate,\n","    )\n","\n","    noise_scheduler = DDPMScheduler.from_config(args.pretrained_model_name_or_path, subfolder=\"scheduler\")\n","\n","    train_dataset = DreamBoothDataset(\n","        instance_data_root=args.instance_data_dir,\n","        instance_prompt=args.instance_prompt,\n","        class_data_root=args.class_data_dir if args.with_prior_preservation else None,\n","        class_prompt=args.class_prompt,\n","        tokenizer=tokenizer,\n","        size=args.resolution,\n","        center_crop=args.center_crop,\n","    )\n","\n","    def collate_fn(examples):\n","        input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n","        pixel_values = [example[\"instance_images\"] for example in examples]\n","\n","        # concat class and instance examples for prior preservation\n","        if args.with_prior_preservation:\n","            input_ids += [example[\"class_prompt_ids\"] for example in examples]\n","            pixel_values += [example[\"class_images\"] for example in examples]\n","\n","        pixel_values = torch.stack(pixel_values)\n","        pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n","\n","        input_ids = tokenizer.pad(\n","            {\"input_ids\": input_ids},\n","            padding=\"max_length\",\n","            return_tensors=\"pt\",\n","            max_length=tokenizer.model_max_length\n","        ).input_ids\n","\n","        batch = {\n","            \"input_ids\": input_ids,\n","            \"pixel_values\": pixel_values,\n","        }\n","        return batch\n","\n","    train_dataloader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=args.train_batch_size, shuffle=True, collate_fn=collate_fn\n","    )\n","\n","    lr_scheduler = get_scheduler(\n","        args.lr_scheduler,\n","        optimizer=optimizer,\n","        num_warmup_steps=args.lr_warmup_steps * args.gradient_accumulation_steps,\n","        num_training_steps=args.max_train_steps * args.gradient_accumulation_steps,\n","    )\n","\n","    if args.train_text_encoder:\n","        unet, text_encoder, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n","            unet, text_encoder, optimizer, train_dataloader, lr_scheduler\n","        )\n","    else:\n","        unet, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n","            unet, optimizer, train_dataloader, lr_scheduler\n","        )\n","\n","    weight_dtype = torch.float32\n","    if accelerator.mixed_precision == \"fp16\":\n","        weight_dtype = torch.float16\n","    elif accelerator.mixed_precision == \"bf16\":\n","        weight_dtype = torch.bfloat16\n","\n","    # Move text_encode and vae to gpu.\n","    # For mixed precision training we cast the text_encoder and vae weights to half-precision\n","    # as these models are only used for inference, keeping weights in full precision is not required.\n","    vae.to(accelerator.device, dtype=weight_dtype)\n","    vae.decoder.to(\"cpu\")\n","    if not args.train_text_encoder:\n","        text_encoder.to(accelerator.device, dtype=weight_dtype)\n","\n","    # We need to recalculate our total training steps as the size of the training dataloader may have changed.\n","    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n","    num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n","\n","    # Train!\n","    total_batch_size = args.train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n","\n","    logger.info(\"***** Running training *****\")\n","    logger.info(f\"  Num examples = {len(train_dataset)}\")\n","    logger.info(f\"  Instantaneous batch size per device = {args.train_batch_size}\")\n","    logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n","    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n","    logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n","\n","    # Only show the progress bar once on each machine.\n","    progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n","    progress_bar.set_description(\"Steps\")\n","    global_step = 0\n","\n","    for epoch in range(num_train_epochs):\n","        unet.train()\n","        for step, batch in enumerate(train_dataloader):\n","            with accelerator.accumulate(unet):\n","                # Convert images to latent space\n","                latents = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype)).latent_dist.sample()\n","                latents = latents * 0.18215\n","\n","                # Sample noise that we'll add to the latents\n","                noise = torch.randn_like(latents)\n","                bsz = latents.shape[0]\n","                # Sample a random timestep for each image\n","                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n","                timesteps = timesteps.long()\n","\n","                # Add noise to the latents according to the noise magnitude at each timestep\n","                # (this is the forward diffusion process)\n","                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n","\n","                # Get the text embedding for conditioning\n","                encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n","\n","                # Predict the noise residual\n","                noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n","\n","                # Get the target for loss depending on the prediction type\n","                if noise_scheduler.config.prediction_type == \"epsilon\":\n","                    target = noise\n","                elif noise_scheduler.config.prediction_type == \"v_prediction\":\n","                    target = noise_scheduler.get_velocity(latents, noise, timesteps)\n","                else:\n","                    raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n","\n","                if args.with_prior_preservation:\n","                    # Chunk the noise and noise_pred into two parts and compute the loss on each part separately.\n","                    noise_pred, noise_pred_prior = torch.chunk(noise_pred, 2, dim=0)\n","                    target, target_prior = torch.chunk(target, 2, dim=0)\n","\n","                    # Compute instance loss\n","                    loss = F.mse_loss(noise_pred.float(), target.float(), reduction=\"none\").mean([1, 2, 3]).mean()\n","\n","                    # Compute prior loss\n","                    prior_loss = F.mse_loss(noise_pred_prior.float(), target_prior.float(), reduction=\"mean\")\n","\n","                    # Add the prior loss to the instance loss.\n","                    loss = loss + args.prior_loss_weight * prior_loss\n","                else:\n","                    loss = F.mse_loss(noise_pred.float(), target.float(), reduction=\"mean\")\n","\n","                accelerator.backward(loss)\n","\n","                if accelerator.sync_gradients:\n","                    params_to_clip = (\n","                        itertools.chain(unet.parameters(), text_encoder.parameters())\n","                        if args.train_text_encoder\n","                        else unet.parameters()\n","                    )\n","                    accelerator.clip_grad_norm_(unet.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","            # Checks if the accelerator has performed an optimization step behind the scenes\n","            if accelerator.sync_gradients:\n","                progress_bar.update(1)\n","                global_step += 1\n","\n","                if global_step % args.save_steps == 0:\n","                    if accelerator.is_main_process:\n","                        pipeline = StableDiffusionPipeline.from_pretrained(\n","                            args.pretrained_model_name_or_path,\n","                            unet=accelerator.unwrap_model(unet),\n","                            text_encoder=accelerator.unwrap_model(text_encoder),\n","                        )\n","                        save_path = os.path.join(args.output_dir, f\"checkpoint-{global_step}\")\n","                        pipeline.save_pretrained(save_path)\n","\n","            logs = {\"loss\": loss.detach().item()}\n","            progress_bar.set_postfix(**logs)\n","\n","            if global_step >= args.max_train_steps:\n","                break\n","\n","        accelerator.wait_for_everyone()\n","\n","    # Create the pipeline using using the trained modules and save it.\n","    if accelerator.is_main_process:\n","        pipeline = StableDiffusionPipeline.from_pretrained(\n","            args.pretrained_model_name_or_path,\n","            unet=accelerator.unwrap_model(unet),\n","            text_encoder=accelerator.unwrap_model(text_encoder),\n","        )\n","        pipeline.save_pretrained(args.output_dir)"]},{"cell_type":"markdown","metadata":{"id":"jin5U_VLh9iU"},"source":["### Run Training"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["cf22293f96d744bf8d3e0783278406e8","5f18044347574d57ab17f96281916420","02bbb9008628414484eee23f19f9aaf1","8e8ecadd08fa486eb0a4f45cb2f76774","dd7cfc0d5af94644ae63826aa494c553","034b7f1778a54bac9e77366fc2d9e586","83a7193d2a69478eb8786d50f8654040","b40f176efd084d11a0a81edf6e28a2ef","c87dcf7e155645d8ab0cc93cf88c819e","9c63488b20da4931aea7b34fec4c5359","22f1ead178c646c1821de5443d04f8ee","f99ffa5caf1547589a92196d4df8d5c4","e86c7704a1004029a0ba1ea9e9309c63","bb3cc650f49646e7a42dc62af1c14e8a","0dd2db97d8f44416838b6615edce9012","0b28dda4ff3a4b8989cd75150210592a","08c40baeca9b4509868a6f2ea89e648a","77d8666b8c484c4ba7da99cc8b60fe42","f724b290fabb4f8f95730940db3f6fa1","3b31937e1b2c4fb4a1618aadc60508a0","c91d4955b8044939978d1562b2f9f7d8","66411828eb3a406682895cd3def6f9fe","41cc6fe395f24ab191a777fbf8e9b87d","3fff116b39634e0480672ed846a1fbfc","f2648d29c8a84108b05c780362b10ffd","fe0cb0fc4afc442b8afe6aed593ba9fe","6a8ec77fb5b0437a84bdf8e63f2c52ee","aad77b7e3d3e4b14a6bc35c6898674b2","562eacd16cf341f889f67e2ce44f8aa9","286fe80cca114dd1a22accae1eec3b3c","7abac13b79f44c789561e2ed6b4eb0ee","1bf90384a9e24d31b4b21da88f6bc632","c339bfdbde62442eb7c5a0da0d89bdbd","1bf349698ad0434f90210a694c2a4bf8","fb0262add7f74604b9d3151c003ae834","cfa16bc38b0d4c65a0e7159882b9db9c","a8055aeccb1b45ee8826aefd93f50419","04df689fb26541798cb7dc23105a94e4","d3c9678e01544c389ae304d7f4b24fe5","37848f3b7710414398568ad735260f39","1ca9d76da2c540e29b33340868c2ee89","be6541b445cc4837996747183d6d2d1e","c27675590bf14918914b09551f00798a","fa1592dd084a4f019b26d196513d5046"]},"executionInfo":{"elapsed":1187623,"status":"ok","timestamp":1695384171455,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"idhthX0kh9iU","outputId":"9054d02a-322a-455a-f7cd-54d9a11fc0ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Launching training on one GPU.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:203: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n","  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf22293f96d744bf8d3e0783278406e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f99ffa5caf1547589a92196d4df8d5c4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ain/model_index.json:   0%|          | 0.00/537 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41cc6fe395f24ab191a777fbf8e9b87d","version_major":2,"version_minor":0},"text/plain":["Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1bf349698ad0434f90210a694c2a4bf8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)rocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import accelerate\n","accelerate.notebook_launcher(training_function, args=(text_encoder, vae, unet))\n","for param in itertools.chain(unet.parameters(), text_encoder.parameters()):\n","  if param.grad is not None:\n","    del param.grad  # free some memory\n","  torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"YP94fjxsh9iU"},"source":["# Inference\n","### Setting Up the Pipeline"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":34304,"status":"ok","timestamp":1695384224905,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"2_LbRZ-6h9iU"},"outputs":[],"source":["from diffusers import DPMSolverMultistepScheduler\n","try:\n","    pipe\n","except NameError:\n","    pipe = StableDiffusionPipeline.from_pretrained(\n","        args.output_dir,\n","        scheduler = DPMSolverMultistepScheduler.from_pretrained(args.output_dir, subfolder=\"scheduler\"),\n","        torch_dtype=torch.float16,\n","    ).to(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"G386NqFYh9iU"},"source":["### Run the Pipeline"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":804,"output_embedded_package_id":"1-rdU4UUf9mNqMOzhriQ5KX2-LITEPmgd","referenced_widgets":["2211107209314f7abf3d253a7923b57b","dc2947e422b143b59be41ac9ab67168e","c92409c3536b426fb4a225a3ad844c6f","dcfe4b015bd34280afe1748c819d38c2","1d702ba732cd48488fb5496b00b887f6","ab153ea6a963410c8812ddf0e176bff3","5e1abfa83f4e4d1eb7f45606fa07b861","fa83f8b7a22f4e11bb83c7e5fcf4eee0","ff038cd6d8624d5fa49135bfe6922ed9","a18d269ed9874f97a47d312679be8c4d","a983fb6664a14701ab46ccd8f4e36b1f"]},"executionInfo":{"elapsed":26422,"status":"ok","timestamp":1695384941729,"user":{"displayName":"Buğrahan Dönmez","userId":"08408275485306519668"},"user_tz":-180},"id":"okykvBUlh9iU","outputId":"c6c60f94-69ce-457d-c44b-38ab3125f08b"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["prompt = \"a \\u003Cteddy-bear> as an actor in front of hollywood sign\" #@param {type:\"string\"}\n","\n","num_samples = 2 #@param {type:\"number\"}\n","num_rows = 1 #@param {type:\"number\"}\n","\n","all_images = []\n","for _ in range(num_rows):\n","    images = pipe(prompt, num_images_per_prompt=num_samples, num_inference_steps=25, guidance_scale=9).images\n","    all_images.extend(images)\n","\n","grid = image_grid(all_images, num_rows, num_samples)\n","grid"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"02bbb9008628414484eee23f19f9aaf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b40f176efd084d11a0a81edf6e28a2ef","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c87dcf7e155645d8ab0cc93cf88c819e","value":300}},"034b7f1778a54bac9e77366fc2d9e586":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04df689fb26541798cb7dc23105a94e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c40baeca9b4509868a6f2ea89e648a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b28dda4ff3a4b8989cd75150210592a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dd2db97d8f44416838b6615edce9012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c91d4955b8044939978d1562b2f9f7d8","placeholder":"​","style":"IPY_MODEL_66411828eb3a406682895cd3def6f9fe","value":" 537/537 [00:00&lt;00:00, 26.2kB/s]"}},"1bf349698ad0434f90210a694c2a4bf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb0262add7f74604b9d3151c003ae834","IPY_MODEL_cfa16bc38b0d4c65a0e7159882b9db9c","IPY_MODEL_a8055aeccb1b45ee8826aefd93f50419"],"layout":"IPY_MODEL_04df689fb26541798cb7dc23105a94e4"}},"1bf90384a9e24d31b4b21da88f6bc632":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca9d76da2c540e29b33340868c2ee89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d702ba732cd48488fb5496b00b887f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2211107209314f7abf3d253a7923b57b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc2947e422b143b59be41ac9ab67168e","IPY_MODEL_c92409c3536b426fb4a225a3ad844c6f","IPY_MODEL_dcfe4b015bd34280afe1748c819d38c2"],"layout":"IPY_MODEL_1d702ba732cd48488fb5496b00b887f6"}},"22f1ead178c646c1821de5443d04f8ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286fe80cca114dd1a22accae1eec3b3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37848f3b7710414398568ad735260f39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b31937e1b2c4fb4a1618aadc60508a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fff116b39634e0480672ed846a1fbfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aad77b7e3d3e4b14a6bc35c6898674b2","placeholder":"​","style":"IPY_MODEL_562eacd16cf341f889f67e2ce44f8aa9","value":"Fetching 13 files: 100%"}},"41cc6fe395f24ab191a777fbf8e9b87d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fff116b39634e0480672ed846a1fbfc","IPY_MODEL_f2648d29c8a84108b05c780362b10ffd","IPY_MODEL_fe0cb0fc4afc442b8afe6aed593ba9fe"],"layout":"IPY_MODEL_6a8ec77fb5b0437a84bdf8e63f2c52ee"}},"562eacd16cf341f889f67e2ce44f8aa9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e1abfa83f4e4d1eb7f45606fa07b861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f18044347574d57ab17f96281916420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_034b7f1778a54bac9e77366fc2d9e586","placeholder":"​","style":"IPY_MODEL_83a7193d2a69478eb8786d50f8654040","value":"Steps: 100%"}},"66411828eb3a406682895cd3def6f9fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a8ec77fb5b0437a84bdf8e63f2c52ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d8666b8c484c4ba7da99cc8b60fe42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7abac13b79f44c789561e2ed6b4eb0ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83a7193d2a69478eb8786d50f8654040":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e8ecadd08fa486eb0a4f45cb2f76774":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c63488b20da4931aea7b34fec4c5359","placeholder":"​","style":"IPY_MODEL_22f1ead178c646c1821de5443d04f8ee","value":" 300/300 [20:12&lt;00:00,  3.14s/it, loss=0.522]"}},"9c63488b20da4931aea7b34fec4c5359":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a18d269ed9874f97a47d312679be8c4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8055aeccb1b45ee8826aefd93f50419":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c27675590bf14918914b09551f00798a","placeholder":"​","style":"IPY_MODEL_fa1592dd084a4f019b26d196513d5046","value":" 342/342 [00:00&lt;00:00, 13.8kB/s]"}},"a983fb6664a14701ab46ccd8f4e36b1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad77b7e3d3e4b14a6bc35c6898674b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab153ea6a963410c8812ddf0e176bff3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b40f176efd084d11a0a81edf6e28a2ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3cc650f49646e7a42dc62af1c14e8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f724b290fabb4f8f95730940db3f6fa1","max":537,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b31937e1b2c4fb4a1618aadc60508a0","value":537}},"be6541b445cc4837996747183d6d2d1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c27675590bf14918914b09551f00798a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c339bfdbde62442eb7c5a0da0d89bdbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87dcf7e155645d8ab0cc93cf88c819e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c91d4955b8044939978d1562b2f9f7d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92409c3536b426fb4a225a3ad844c6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa83f8b7a22f4e11bb83c7e5fcf4eee0","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff038cd6d8624d5fa49135bfe6922ed9","value":25}},"cf22293f96d744bf8d3e0783278406e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f18044347574d57ab17f96281916420","IPY_MODEL_02bbb9008628414484eee23f19f9aaf1","IPY_MODEL_8e8ecadd08fa486eb0a4f45cb2f76774"],"layout":"IPY_MODEL_dd7cfc0d5af94644ae63826aa494c553"}},"cfa16bc38b0d4c65a0e7159882b9db9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca9d76da2c540e29b33340868c2ee89","max":342,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be6541b445cc4837996747183d6d2d1e","value":342}},"d3c9678e01544c389ae304d7f4b24fe5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc2947e422b143b59be41ac9ab67168e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab153ea6a963410c8812ddf0e176bff3","placeholder":"​","style":"IPY_MODEL_5e1abfa83f4e4d1eb7f45606fa07b861","value":"100%"}},"dcfe4b015bd34280afe1748c819d38c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a18d269ed9874f97a47d312679be8c4d","placeholder":"​","style":"IPY_MODEL_a983fb6664a14701ab46ccd8f4e36b1f","value":" 25/25 [00:17&lt;00:00,  1.44it/s]"}},"dd7cfc0d5af94644ae63826aa494c553":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e86c7704a1004029a0ba1ea9e9309c63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c40baeca9b4509868a6f2ea89e648a","placeholder":"​","style":"IPY_MODEL_77d8666b8c484c4ba7da99cc8b60fe42","value":"Downloading (…)ain/model_index.json: 100%"}},"f2648d29c8a84108b05c780362b10ffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_286fe80cca114dd1a22accae1eec3b3c","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7abac13b79f44c789561e2ed6b4eb0ee","value":13}},"f724b290fabb4f8f95730940db3f6fa1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99ffa5caf1547589a92196d4df8d5c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e86c7704a1004029a0ba1ea9e9309c63","IPY_MODEL_bb3cc650f49646e7a42dc62af1c14e8a","IPY_MODEL_0dd2db97d8f44416838b6615edce9012"],"layout":"IPY_MODEL_0b28dda4ff3a4b8989cd75150210592a"}},"fa1592dd084a4f019b26d196513d5046":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa83f8b7a22f4e11bb83c7e5fcf4eee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb0262add7f74604b9d3151c003ae834":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c9678e01544c389ae304d7f4b24fe5","placeholder":"​","style":"IPY_MODEL_37848f3b7710414398568ad735260f39","value":"Downloading (…)rocessor_config.json: 100%"}},"fe0cb0fc4afc442b8afe6aed593ba9fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bf90384a9e24d31b4b21da88f6bc632","placeholder":"​","style":"IPY_MODEL_c339bfdbde62442eb7c5a0da0d89bdbd","value":" 13/13 [00:00&lt;00:00,  2.51it/s]"}},"ff038cd6d8624d5fa49135bfe6922ed9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
